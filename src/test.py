#===============================================================================
# import numpy as np
# import pandas as pd
# from datasetdeal import *
# from ensemblemethods import *
# from sklearn.model_selection._split import KFold
# 
# #===============================================================================
# # path=r'D:\Codetool\datasrc\imbalancedata\moredata\glass\glass-0-4_vs_5\addresult.csv'
# # bdata=[1,2,3,4,5]
# # adata=[11,22,33,44,55]
# # data=[]
# # data.append(adata)
# # data.append(bdata)
# # datastr=np.array(data)
# # print(datastr.shape)
# # datastr=datastr.T
# # print(datastr.shape)
# # datastr=pd.DataFrame(datastr)
# # datastr.to_csv(path,mode='a',header = False, index = False)
# # print('this is ok')
# #===============================================================================
# #ot=input('请输入要进行训练的数据集序号')
# ot=2
# posarray,negarray,_,_=get33Data(int(ot))
# print(posarray.shape,negarray.shape)
# kf=KFold(5,shuffle=True)
# fivetimescore=[]
# for (pos_trainindex,pos_testindex),(neg_trainindex,neg_testindex) in zip(kf.split(posarray),kf.split(negarray)):
#     pos_train,pos_test=posarray[pos_trainindex],posarray[pos_testindex]
#     neg_train,neg_test=negarray[neg_trainindex],negarray[neg_testindex]
#     each_cartscore=cart_GetScore(pos_train, pos_test, neg_train, neg_test)
#     fivetimescore.append(each_cartscore)
#     print(each_cartscore)
# 
# print(fivetimescore[0])
# print(fivetimescore[1])
#===============================================================================

#===============================================================================
# import numpy as np
# a=[[1,2,3],[2,3,4]]
# a_array=np.array(a)
# b=[[3,4,5],[4,5,6]]
# c=np.vstack((a,b))
# idx=[0,1,2]
# d=c[idx]
# print(type(d))
#===============================================================================


#===============================================================================
# from collections import Counter
# from sklearn.datasets import make_classification
# from sklearn.model_selection import train_test_split
# from sklearn.metrics import confusion_matrix
# from imblearn.ensemble import EasyEnsembleClassifier 
# X, y = make_classification(n_classes=2, class_sep=2,
# weights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0,
# n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)
# print('Original dataset shape %s' % Counter(y))
# X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=0)
# eec = EasyEnsembleClassifier(random_state=42)
# eec.fit(X_train, y_train) 
# 
# y_pred = eec.predict(X_test)
# print(confusion_matrix(y_test, y_pred))
#===============================================================================

#===============================================================================
# import numpy as np
# a=[1,2,3,4,5]
# print(np.mean(a))
# print(np.std(a))
#===============================================================================

#===============================================================================
# a='a'
# b='b'
# c='c'
# l1=[(a,1),(b,3),(c,2)]
# d='d'
# dd=35
# l1.append((d,dd))
# print(l1)
# print(l1[1][1])
# l1.sort(key=lambda x:x[1], reverse=False)
# print(l1[1][1])
# l2=[]
# for x in l1:
#     l2.append((x[0],x[1]/5))
# print(l2)
#===============================================================================


#===============================================================================
# import numpy as np
# a=np.array([1,3,2,5,7,4])
# b=np.array([3,3,2,5,7,4])
# c=np.sum(a**2)
# print(c)
# d=np.array([4,3])
# print(np.linalg.norm(d))
#===============================================================================




#===============================================================================
# import random as rd
# a=rd.random()
# print(a)
# print(3+6/5)
# sum=0
# for i in range(100):
#     print('test i',i)
#     for j in range(20):
#         print('test j',j)
#         if j==10:
#             break
#     sum=i
# print('end:',sum)
#===============================================================================
        
#===============================================================================
# from collections import Counter
# from sklearn.datasets import make_classification
# from imblearn.over_sampling import SMOTE 
# X, y = make_classification(n_classes=2, class_sep=2,
# weights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0,
# n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)
# print('Original dataset shape %s' % Counter(y))
# print(len(X),len(y))
# sm = SMOTE(random_state=42)
# X_res, y_res = sm.fit_resample(X, y)
# print('Resampled dataset shape %s' % Counter(y_res))
#===============================================================================

#===============================================================================
# from scipy.stats import wilcoxon,mannwhitneyu,ranksums
# #a=[214, 159, 169, 202, 103, 119, 200, 109, 132, 142, 194, 104, 219, 119, 234]
# #b=[159, 135, 141, 101, 102, 168, 62, 167, 174, 159, 66, 118, 181, 171, 112]
# 
# a=[0.893333333,0.98150787,0.967836257,1,0.748941799,0.824868072,0.954471545,0.972747748,0.665278795,0.791298327,0.932629462,0.942402097,0.474958183,0.748577411,0.864835742,0.872858885,0.668585489,0.881223975,0.918181818,0.951875,0.659047184,0.908454228,0.913288554,0.969636009,0.121654642,0.229562506,0.840260909,0.737063492,0.098888889,0.146032449,0.905411255,0.783563034,0.617285156,0.879373305,0.907836929,0.949952994,0.566677688,0.886437465,0.882536413,0.960351246,0.79003848,0.920125317,0.959722222,0.98219697,0.692169312,0.947156479,0.907272727,0.977324561,0.214692715,0.433095355,0.84259969,0.753356646,0.66222466,0.847224295,0.938655209,0.956040895,0.329206349,0.466974413,0.913333333,0.877256944,0.666666667,0.803434239,0.95,0.978846154,0.745329714,0.969719361,0.953538761,0.997461908,0.316304066,0.524135078,0.915782768,0.815940112,0.592539683,0.880301219,0.925192121,0.963062331,0.626224886,0.894308478,0.935586772,0.983205192,0.585761395,0.858991491,0.930045315,0.969405289,0.333486864,0.683512617,0.873243851,0.81258867,0.546349206,0.793226849,0.94009009,0.979047619,0.748888889,0.883699471,0.969105413,0.889333333,0.165689915,0.449525374,0.874959163,0.706255221,0.552380952,0.833096221,0.943816907,0.973577236,0.662539683,0.723571822,0.979259737,0.797286505,0.329474498,0.782775609,0.904773219,0.916592432,0.278388278,0.425021895,0.964455583,0.747879379,0.606011288,0.940613951,0.963614372,0.989220036,0.484761905,0.730717883,0.967957773,0.946621773,0.503419946,0.797831511,0.968331968,0.936420361,0,0,0.992334171,0.810332335]
# b=[0.822222222,0.965698298,0.940167412,1,0.730644541,0.840607212,0.946341463,0.965765766,0.751798757,0.872540359,0.944419306,0.952713537,0.478456933,0.750424689,0.864936337,0.869154572,0.711818182,0.892611035,0.921212121,0.96125,0.662067238,0.897856267,0.916676067,0.964153332,0.094179894,0.174718862,0.850877193,0.696904762,0.033333333,0.038490018,0.896176046,0.739821937,0.601304085,0.8715565,0.902890627,0.940528233,0.553745899,0.872162012,0.877260054,0.956243189,0.773703704,0.916086031,0.955555556,0.986742424,0.684074074,0.932466067,0.912424242,0.971666667,0.196174196,0.369537188,0.829107627,0.77571914,0.663122803,0.862739718,0.933770541,0.954047241,0.401269841,0.554884744,0.920896359,0.887847222,0.68012025,0.829076105,0.953571429,0.976923077,0.72149992,0.958434938,0.94878047,0.994114472,0.253679654,0.38790425,0.917247969,0.823168415,0.558465608,0.838441408,0.9205074,0.942588076,0.618171828,0.877911798,0.930494586,0.973222553,0.554667685,0.851114522,0.923676304,0.959086937,0.322182287,0.650541518,0.88414348,0.819111339,0.600634921,0.851723335,0.949199199,0.98,0.737777778,0.79452527,0.979179487,0.901111111,0.156052884,0.479469222,0.865846453,0.68692628,0.546349206,0.770937269,0.947065338,0.956097561,0.671587302,0.729976822,0.979274055,0.813843112,0.328407377,0.757840827,0.909494633,0.912487147,0.254814815,0.371291048,0.965157338,0.760963445,0.598317567,0.913535337,0.964067097,0.98670589,0.581111111,0.824792351,0.968211438,0.963827161,0.454139016,0.753617015,0.965410107,0.939027108,0,0,0.992334171,0.796854238]
# c=[0.813650794,0.969242274,0.946152964,0.976102941,0.704179894,0.7808703,0.951219512,0.885135135,0.648802309,0.724551823,0.948139769,0.800459451,0.337542143,0.619213407,0.823353458,0.765683247,0.711428571,0.79085555,0.953030303,0.855833333,0.524948291,0.792187409,0.883580304,0.904771076,0.166253006,0.343043472,0.831848853,0.683571429,0.120586821,0.255539987,0.857864358,0.77732906,0.47829201,0.714533789,0.892982946,0.853629473,0.46127595,0.710374099,0.886509855,0.892781864,0.528253968,0.62336713,0.938888889,0.891477273,0.547301587,0.736234333,0.89969697,0.917631579,0.155486365,0.317567726,0.832837786,0.761105184,0.358412698,0.46042792,0.935745515,0.881537106,0.336666667,0.49342535,0.905714286,0.8234375,0.632222222,0.727732499,0.955952381,0.896955128,0.836261204,0.985521884,0.973203005,0.998640337,0.117835498,0.226621995,0.902715401,0.733093935,0.427619048,0.663294053,0.906404577,0.895948509,0.601587302,0.761280838,0.951419374,0.913355655,0.716469413,0.882702714,0.961177618,0.962997957,0.127607246,0.383510215,0.826747687,0.684754619,0.40047619,0.686259845,0.922222222,0.948571429,0.742222222,0.916854295,0.966548908,0.987333333,0.099191516,0.37617538,0.813411879,0.560245943,0.338888889,0.561117502,0.926873385,0.939430894,0.304126984,0.365023147,0.961963058,0.738991156,0.004761905,0.020447945,0.904306167,0.758806397,0.144657565,0.260151072,0.950017637,0.714769442,0.426177856,0.718235437,0.955529772,0.948705954,0.397777778,0.562751584,0.969254196,0.796318743,0.246731539,0.505638767,0.959570176,0.890797723,0,0,0.992334171,0.751225516]
# b=c
# w,p=wilcoxon(a, b,alternative='greater')
# w1,p1=wilcoxon(a, b,alternative='less')
# w2,p2=wilcoxon(a, b,alternative='two-sided')
# print(w,'\n',p)
# print(w1,'\n',p1)
# print(w2,'\n',p2)
#===============================================================================

#w,p=mannwhitneyu(a,b)
#w,p=mannwhitneyu(b,a)
#w,p=ranksums(a,b)
#w1,p1=wilcoxon(a, b,alternative='less')
#w2,p2=wilcoxon(a, b,alternative='two-sided')
#print(w,'\n',p)
#print(w1,'\n',p1)
#print(w2,'\n',p2)


from buchongshiyan import *
import time
#res=smotebagaddFourScoreSignle(33)


for i in range(33,43):
    start=time.time()
    res=brfFourScoreSignle(i)
    #res=usendFourScoreSignle(i)
    #res=mmboostFourScoreSignle(i)
    #res=smoteboostFourScoreSignle(i)
    #res=smotebagaddFourScoreSignle(i)
    #res=ubagFourScoreSignle(i)
    #res=easyenFourScoreSignle(i)
    end=time.time()
    print(res)
    print("runtime：",end-start)

#===============================================================================
# starttime=time.time()
# res=mmboostFourScoreSignle(39)
# endtime=time.time()
# print(res)
# print("runtime:",endtime-starttime)
#===============================================================================

print("this is end")








    
